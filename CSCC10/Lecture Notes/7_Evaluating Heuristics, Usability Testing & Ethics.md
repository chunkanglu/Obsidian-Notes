---
tags:
  - CSCC10
---
# Evaluation
- iterative design and evaluation is a continuous process to examine:
	- Why (evaluate)
	- What (are we evaluating)
	- Where (are we evaluating)
		- controlled lab or natural setting
	- When (are we evaluating)
		- how frequently (sprint design, gradual)
		- early on, or later, every stage of process
# Types of Evaluation
## Controlled settings
- usability test labs
- researcher sees user but user cannot see to observe
- everything easily logged
## Natural setting
- in the field in the setting of the user using the product
- evaluation too difficult to do in a usability lab
## Settings not involving users
- research or expert critique (from UX designers)
- predictive methods to identify usability problems
# Data Gathering - Controlled setting
- can use same data gathering techniques when evaluating
- use more high fidelity props and think-aloud technique to get participant thoughts
- More use of video recording
## Informed Consent
- purpose of why evaluation is done
	- do so without bias
- participation is voluntary with informed consent, can withdraw at any time
- design of informed consent form, evaluation process, data analysis and data storage methods must be reviewed by high authority
- where is data stored, is it published, how long data is kept, incentives
# Data Collection
- continuous user-performance data logging
	- patterns of usage
	- automated evaluation tools
# Natural settings
- field studies
- can be combined with controlled settings for more rich data
# Expert Reviews & Heuristics
## Heuristic Evaluation
Review guided by set of recognized usability principles (heuristics)
10 principles developed by Jacob Nielsen in the early 90s, and revised after
- number of evaluators to find problems non-linear
- on average 5 evaluators (3-5 actually) identify 75-80% of usability problems, more leads to saturation
#### 10 principles
1. Visibility of system status
	1. system should always keep user informed, with feedback withing reasonable time
	2. eg. prompt saying message has been sent, complete icons, progress bars
2. Match between system and real world
	1. system should use same language as used by user
	2. follow real-world conventions, making information appear in natural and logical order
	3. eg. icon matching
3. User control and freedom
	1. clear emergency exit to leave unwanted states if users make mistakes
	2. eg. undo, delete, recovery
4. Consistency and standards
	1. platform conventions should mean similar things
5. Error Prevention
	1. Good error messages prevents problem in the first place
	2. eliminate error-prone conditions or check them
	3. eg. give user prompts about mistakes or problems as they are typing
6. Recongnition rather than recall
	1. minimize memory load by making objects and options visible
7. Flexibility and efficiency
8. Aesthetic and minimal design
	1. simplistic designs
9. Help users recognize, diagnose, recover from errors
	1. error messages should be easy to understand, indicate problem, and constructively suggest a solution
10. Help and documentation
	1. system documentation should be easy to search, focused on user tasks
	2. even though product should be usable without documentation, it should still be present
#### Heuristic evaluation steps
- checklist of what to evaluate
- experts should split off, go though and find issues
- consolidate findings after everyone finished