---
tags:
  - CSCC37
  - C37Assignment
---
## 1a
page 66 in tb
$m_k$ multipliers
## 1b
## 1c
## 1d
For single swap row permutation matrices, the square of it is the identity since it swaps two rows and then swaps the same two rows back. $P_i^{2} = I$.
## 2a
How do we get from $L_4P_4L_3P_3L_2P_2L_1P_1A = U$ to $P_4P_3P_2P_1A = \tilde{L}_1^{-1}\tilde{L}_2^{-1}\tilde{L}_3^{-1}L_4^{-1}U$?
$$
\begin{align}
L_4\tilde{L}_3\tilde{L}_2\tilde{L}_1P_4P_3P_2P_1A = U \\
L_4\tilde{L}_3\tilde{L}_2(P_4P_3P_2L_1P_2P_3P_4)P_4P_3P_2P_1A \\
L_4\tilde{L}_3\tilde{L}_2P_4P_3P_2L_1P_1A = U \\
L_4\tilde{L}_3(P_4P_3L_2P_3P_4)P_4P_3P_2L_1P_1A \\
L_4\tilde{L}_3P_4P_3L_2P_2L_1P_1A = U \\
L_4(P_4L_3P_4)P_4P_3L_2P_2L_1P_1A = U \\
L_4P_4L_3P_3L_2P_2L_1P_1A = U \\
\end{align}
$$
$$
\begin{align}
\tilde{L}_1 &= P_4P_3P_2L_1P_2P_3P_4 \\
\tilde{L}_2 &= P_4P_3L_2P_3P_4 \\
\tilde{L}_3 &= P_4L_3P_4 \\
\tilde{L}_1^{-1} &= (P_4P_3P_2L_1P_2P_3P_4)^{-1} \\
&= P_4^{-1}P_3^{-1}P_2^{-1}L_1^{-1}P_2^{-1}P_3^{-1}P_4^{-1}
\end{align}
$$
## 2b
$$
P_1 = 
\begin{bmatrix}
0 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1
\end{bmatrix}
, ~
P_2 = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 & 0
\end{bmatrix}
, ~
P_3 = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1
\end{bmatrix}
, ~
P_4 = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0
\end{bmatrix}
$$
$$
P_1^{-1} = P_1^T = 
\begin{bmatrix}
0 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1
\end{bmatrix}
, ~
P_2^{-1} = P_2^T = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 & 0
\end{bmatrix}
, ~
P_3^{-1} = P_3^T = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1
\end{bmatrix}
, ~
P_4^{-1} = P_4^T = 
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0
\end{bmatrix}
$$
# **TODO:**
## 3a
$$
A =
\begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 4 \\
2 & 1 & 0 & \dots & 0 & 0 \\
0 & 2 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & 0 \\
0 & 0 & 0 & \dots & 2 & 1 \\
\end{bmatrix}
$$
$$
L_{1} =
\begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 \\
-2 & 1 & 0 & \dots & 0 & 0 \\
0 & 0 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & 0 \\
0 & 0 & 0 & \dots & 0 & 1 \\
\end{bmatrix}
,~
L_{1}A =
\begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 4 \\
0 & 1 & 0 & \dots & 0 & -8 \\
0 & 2 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & 0 \\
0 & 0 & 0 & \dots & 2 & 1 \\
\end{bmatrix}
$$
$$
L_{2} =
\begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 \\
0 & 1 & 0 & \dots & 0 & 0 \\
0 & -2 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & 0 \\
0 & 0 & 0 & \dots & 0 & 1 \\
\end{bmatrix}
,~
L_{2}L_{1}A =
\begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 4 \\
0 & 1 & 0 & \dots & 0 & -8 \\
0 & 0 & 1 & \dots & 0 & 16 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & 0 \\
0 & 0 & 0 & \dots & 2 & 1 \\
\end{bmatrix}
$$
Continuing this pattern, we can see that $U = L_n L_{n-1} \dots L_2 L_1 A$ has the form
$$
u_{ij} = 
\begin{cases}
1 & \text{if } i = j; i = 1 \dots n, j = 1 \dots n \\
(-2)^{i+1} & \text{if } j = n; i = 1 \dots n-1 \\
(-2)^{n+1} + 1 & \text{if } j = n, i = n \\
0 & \text{otherwise}
\end{cases}
$$
Now we find the inverses of our Gauss Transforms
$$
L_{1}^{-1} =
\begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 \\
2 & 1 & 0 & \dots & 0 & 0 \\
0 & 0 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & 0 \\
0 & 0 & 0 & \dots & 0 & 1 \\
\end{bmatrix}
,~
L_{2}^{-1} =
\begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 \\
0 & 1 & 0 & \dots & 0 & 0 \\
0 & 2 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & 0 \\
0 & 0 & 0 & \dots & 0 & 1 \\
\end{bmatrix}
,~
L_{1}^{-1} L_{2}^{-1} =
\begin{bmatrix}
1 & 0 & 0 & \dots & 0 & 0 \\
2 & 1 & 0 & \dots & 0 & 0 \\
0 & 2 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 1 & 0 \\
0 & 0 & 0 & \dots & 0 & 1 \\
\end{bmatrix}
$$
We continue this similar pattern to get $L$.
$$
l_{ij} = 
\begin{cases}
1 & \text{if } i = j; i = 1 \dots n, j = 1 \dots n \\
2 & \text{if } i = j + 1; i = 2 \dots n, j = 1 \dots n-1 \\ 
0 & \text{otherwise}
\end{cases}
$$
Which is basically $A$ with the top right $4$ replaced with a $0$.
## 3b
The largest value in magnitude in $\mathbb{R}_{10}(16, 2)$ is $0.\underbrace{99 \ldots 99}_{16} \cdot 10^{99}$. The largest value in magnitude involved in the factorization is the term $(-2)^{n+1} + 1$. Overflow happens when:
$$
\begin{align}
& |(-2)^{n+1} + 1| > 0.\underbrace{99 \ldots 99}_{16} \cdot 10^{99} \\
\implies& 2^{n+1} + 1 > 0.\underbrace{99 \ldots 99}_{16} \cdot 10^{99} & \text{since we only consider magnitude}\\
\implies& n > \log_{2}{\left( 0.\underbrace{99 \ldots 99}_{16} \cdot 10^{99} - 1\right)} - 1  \\
\implies& n > 327 & \text{since $n$ is an integer}
\end{align}
$$
Thus $A$ must have dimensions greater than $327$ for overflow to occur.
## 3c
What is this asking for
Not stable if overflow
## 4a

## 4b

## 4c
underflow is ok and stable we just need to set to 0
## 5a
Can we say it is basically the same algorithm but with different dimension matrices?
m by m gauss trans
L1 is m by m
and m by n needs n gauss transforms

## 5b
this class
## 5c
What is this asking for?
what does it mean to fit a line to 3 points
we are trying to get a close approximate
ax approx b
r = b - ax
we want to make this residual as small as possible since usually no singular solution
find solution such that the normed residual is as small as possible
## 6
next week
when was this derived, i dont think it was
page 58 tb
https://math.stackexchange.com/questions/1998646/finding-lower-bound-with-given-facts-relative-error-and-relative-residual
https://math.stackexchange.com/questions/3383786/proving-a-formula-for-the-error-bound